Architecture
############

Contemporary operating systems are immensely complex to accommodate a
large variety of applications on an ever diversifying spectrum of hardware
platforms. Among the functionalities provided by a commodity operating system
are device drivers, protocol stacks such as file systems and network
protocols, the management of hardware resources, as well as the provisioning
of security functions. The latter category is meant for protecting the
confidentiality and integrity of information and the lifelines of critical
functionality. For assessing the effectiveness of such a security function,
two questions must be considered. First, what is the potential attack surface
on the function? The answer to this question yields an assessment about the
likelihood of a breach. Naturally, if there is a large number of potential
attack vectors, the security function is at high risk. The second question is:
What is the reach of a defect? If the compromised function has unlimited
access to all information processed on the system, the privacy of all users
may be affected. If the function is able to permanently install software, the
system may become prone to back doors.

Today's widely deployed operating systems do not isolate security-critical
functions from the rest of the operating system. In contrary, they are
co-located with most other operating-system functionality in a single
high-complexity kernel. Thereby, those functions are exposed to the other
parts of the operating system. The likelihood for of a security breach is as
high as the likelihood for bugs in the overly complex kernel. In other words,
it is certain. Moreover, once an in-kernel function has been compromised, the
defect has an unlimited reach on the system.

The Genode architecture was designed to give more assuring answers to the two
stated questions. Each piece of functionality should be exposed to only those
parts of the system, on which it ultimately depends. But it remains hidden
from all unrelated parts. This minimizes the attack surface on individual
security functions and thereby reduces the likelihood for a security breach.
In the event that one part of the system gets compromised, the reach of the
defect is limited to the particular part and its dependent parts. But
unrelated functionalities remain unaffected. To realize this idea, Genode
composes the system out of many components that interact with each other. Each
component serves a specific role and uses well-defined interfaces to interact
with its peers. For example, a network driver accesses a physical network card
and provides a bidirectional stream of network packets to another component,
which, in turn, may process the packets using a TCP/IP stack and a network
application. Even though the network driver and the TCP/IP stack cooperate
when processing network packets, they are living in separate protection
domains. So a bug in one component cannot observe or corrupt the internal
state of another.

Such a component-based architecture, however, raises a number of questions,
which are addressed throughout this chapter.
Section [Capability-based security] explains how components can cooperate
without inherently trusting each other.
Section [Recursive system structure] answers the questions of who defines the
relationship between components and how components become acquainted with each
other.
An operating system ultimately acts on physical hardware resources such
as memory, CPUs, and peripheral devices.
Section [Core - the root of the component tree] describes how such resources
are made available to components.
Section [Component creation] answers the question of how a new component comes
to life.
The variety of relationships between components and their respective
interfaces call for different communication primitives. Section
[Inter-component communication] introduces inter-component communication
mechanisms in detail.


Capability-based security
=========================

| TODO intro, possibly provide general background information (independent
| from Genode)

This section introduces the nomenclature and the general model of Genode's
capability-based security concept. The Genode OS framework is not tied to one
kernel but supports a variety of kernels as base platforms. On each of those
base platforms, Genode uses different kernel mechanisms to implement the
general model as closely as possible. Note however that not all kernels
satisfy the requirements that are needed to implement the model securely. For
assessing the security of a Genode-based system, the respective
platform-specific implementation must be considered. Section
[Capability-based security in depth] provides details for selected kernels.


Capability spaces, object identities, and RPC objects
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Each component lives inside a protection domain that provides an isolated
execution environment.

[tikz img/protection_domain]

Genode provides an object-oriented way of letting components interact with
each other. Analogously to object-oriented programming languages, which have
the notion of objects and pointers to objects, Genode introduces the notion of
RPC objects and capabilities to RPC objects.

An _RPC object_ provides a remote-procedure call (RPC) interface. Similar to a
regular object, an RPC object can be constructed and accessed from within the
same program. But in contrast to a regular object, it can also be called from
the outside of the component. What a pointer is to a regular object, a
_capability_ is to an RPC object. It is a token that unambiguously refers to
an RPC object. In the following, we represent an RPC object as follows.

[tikz img/rpc_object]

The circle represents the capability associated with the RPC object. Like a
pointer to an object, that can be used to call a function of the pointed-to
object, a capability can be used to call functions of its corresponding RPC
object. However, there are two important differences between a capability and
a pointer. First, in contrast to a pointer that can be created out of thin air
(e.g., by casting an arbitrary number to a pointer), a capability cannot be
created without an RPC object. At the creation time of an RPC object, Genode
creates a so-called _object identity_ that represents the RPC object in the
kernel. Figure [img/object_identity] illustrates the relationship of an
RPC object and its object identity.

[tikz img/object_identity]
  Relationship between an RPC object and its corresponding object identity.

For each protection domain, the kernel maintains a so-called capability space,
which is a name space that is local to the protection domain. At the creation time of
an RPC object, the kernel creates a corresponding object identity and lets a
slot in the protection domain's capability space refer to the RPC object's
identity. From the component's point of view, the RPC object A has the name 3.
When interacting with the kernel, the component can use this number to refer
to the RPC object A.


Delegation of authority and ownership
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

[tikz img/delegation]
  The transitive delegation of a capability from one protection domain to
  others.

The second difference between a pointer and a capability is that a capability
can be passed to different components without losing its meaning. The transfer
of a capability from one protection domain to another delegates the authority
to use the capability to the receiving protection domain.
This operation is called _delegation_ and can be performed only by the kernel.
Note that originator of the delegation does not diminish its authority by
delegating a capability. It merely shares its authority with the receiving
protection domain.
Figure [img/delegation] shows the
delegation of the RPC object's capability to a second protection domain
and a further delegation of the capability from the second to a third
protection domain.
When the kernel delegates a capability from one to another protection domain,
it inserts a reference to the RPC object's identity a free slot in the
target's capability space. Within protection domain 2, the RPC object can
be referred to by the number 5. Within protection domain 3, the same RPC
object is known as 2.
Note that the capability delegation does not hand over the ownership of the
object identity to the target protection domain. The ownership is always
retained by the protection domain that created the RPC object.

Only the owner of an RPC object is able to destroy it along with the
corresponding object identity. Upon destruction of an object identity, the
kernel removes all references to the vanishing object identity from all
capability spaces. This effectively renders the RPC object inaccessible for
all protection domains. Once the object identity for an RPC object is gone,
the owner can destruct the actual RPC object.


Capability invocation
~~~~~~~~~~~~~~~~~~~~~

Capabilities enable components to call methods of RPC objects
provided by different protection domains. A component that uses
an RPC object plays the role of a _client_ whereas a component that
owns the RPC object acts in the role of a _server_. The interplay between
client and server is very similar to a situation where a program calls
a local function. The caller puts the function arguments to a place where
the callee will be able to pick them up and then passes control to the
callee. When the callee takes over control, it obtains the function
arguments, executes the function, puts the results to a place where the
caller can pick them up, finally hands the control back to the caller.
In contrast to a program-local function call, however, client and server
are different _threads_ in their respective protection domains. The thread
at the server side is called _entrypoint_ denoting the fact that it
becomes active only when a call from a client enters the protection domain.
In order to be able to act as a server, a component has to have at least
one entrypoint.

[tikz img/entrypoint]

The wiggly arrow denotes that the entrypoint is a thread. Besides being a
thread that waits for incoming requests, the entrypoint is responsible for
maintaining the association between RPC objects with their corresponding
capabilities. This association was illustrated by the link between the RPC
object and its capability in the previous figures. In order to become callable
from the outside, an RPC object must be associated with a concrete entrypoint.
This operation results in the creation of the object's identity and the
corresponding capability. During the lifetime of the object identity, the
entrypoint keeps the association between the RPC object and its capability in
a data structure called _object pool_, which allows for looking up the
matching RPC object for a given capability. Figure [img/object_pool] shows a
scenario where two RPC objects are associated with one entrypoint in the
protection domain of a server. The capability for the RPC object A has been
delegated to a client.

[tikz img/object_pool]
  The RPC object A and B are associated with the server's entrypoint.
  A client has a capability for A but not for B.
  For brevity, the kernel-protected object identities are
  not depicted. Instead, the dashed line between the capabilities shows that
  both capabilities refer to the same object identity.

If a protection domain is in possession of a capability, each thread executed
within this protection domain can issue a call to a member function of the RPC
object that is referred to by the capability. Because this is not a normal
function call but the invocation of an object located in a different
protection domain, this operation has to be provided by the kernel. Figure
[img/capability_call] illustrates the interaction of the client, the kernel,
and the server. The kernel operation takes the client-local name of the
invoked capability, the opcode of the called function, and the function
arguments as parameters. When entering the kernel, the client's thread is
blocked until it receives a response. The operation of the kernel is
represented by the dotted line.
The kernel takes the supplied local name as an
index into the client's capability space to look up the object identity, to
which the capability refers. Given the object identity, kernel is able to
determine the entrypoint that is associated with the object identity and wakes
up the entrypoint's thread with the information about the incoming request.
Among those information is the server-local name of the capability that was
invoked. Note that the kernel has translated the client-local name
into the corresponding server-local name. The capability name spaces of client and
server are entirely different. The entrypoint uses this number as a key into
its object pool to find the locally implemented RPC object A that belongs to
the invoked capability. It then performs a method call of the so-called
_dispatch_ function on the RPC object. The dispatch function maps the supplied
function opcode to the matching member function and calls this function
with the request arguments.

[tikz img/capability_call]
  Control flow between client and server when the client calls a method of an
  RPC object.

; We could illustrate the lookup of the RPC object from the object pool.

The member function may produce function results. Once the RPC object's member
function returns, the entrypoint thread passes the function results to the
kernel by performing the kernel's _reply_ operation. At this point, the
server's entrypoint becomes ready for the next request. The kernel, in turn,
passes the function results as return values of the original call operation to
the client and wakes up the client thread.


Capability delegation through capability invocation
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Section [Delegation of authority and ownership] explained that capabilities
can be delegated from one protection domain to another via a kernel operation.
But it left open the question how this procedure works. The answer is the use
of capabilities as RPC message payload. Similar to how a caller of a regular
function can pass a pointer as an argument, a client can pass a capability as
an argument to an RPC call. In fact, passing capabilities as RPC arguments or
results is synonymous to delegating authority between components.
If the kernel encounters a capability as an argument of a call operation, it
performs the steps illustrated in Figure [img/capability_argument].
;
; We direct the following lines directly to LaTeX to parse the math
; environments.
;
: The local names are denoted as $cap$, e.g., $cap_{arg}$
: is the local name of the object identity at the client side, and
: $cap_{translated}$ is the local name of the same object identity at the
: server side.

[tikz img/capability_argument]
  Procedure of delegating a capability specified as RPC argument from a
  client to a server.

# The kernel looks up the object identity in the capability space of the
  client. This lookup may fail if the client specified a number of an empty
  slot of its capability space. Only if the lookup succeeds, the kernel is
  able obtain the object identity referred to by the argument. Note that under
  no circumstances, the client can refer to object identities, for which it
  has no authority because it can merely specify the object identities
  reachable through its capability space. For all non-empty slots of its
  capability space, the protection domain was authorized to use their
  referenced object identities by the means of prior delegations.

# Given the object identity of the argument, the kernel searches the server's
  capability space for a slot that refers to the object identity. Note that
  the term "search" does not necessarily refer to an expensive linear search.
  The efficiency of the operation largely depends on the kernel implementation.

# If the server already possesses a capability to the object identity, the
  kernel translates the argument to the corresponding local name when passing
  it as part of the request to the server. If the server does not yet possess
  a capability to the argument, the kernel installs a new entry into the
  server's capability space. The new entry refers to the object identity of
  the argument. At this point, the authority over the object identity has been
  delegated from the client to the server.

# The kernel passes the just-created local name of the argument as part of the
  request to the server. Even though the above description covered the
  delegation of a single capability specified as argument, it is possible to
  delegate more than one capability with a single RPC call.

Analogously to how capabilities can be delegated from a client to a server as
arguments of an RPC call, capabilities can be delegated in the other direction
as part of the reply of an RPC call. The procedure in the kernel is the same
in both cases.


\clearpage

Recursive system structure
==========================

The previous section introduced capability delegation as the fundamental
mechanism to pass authority over RPC objects between protection domains. But
in the given examples, the client was already in possession to a capability to
the server's RPC object. This raises the question of how do clients get
acquainted to servers?


Component ownership
~~~~~~~~~~~~~~~~~~~

In a Genode system, each component (except for the initial component called
core) has a parent, which owns the component. The _ownership_ relation between
a parent and a child is two-fold.

[tikz img/parent_child]

On the one hand, ownership stands for _responsibility_. The parent is
responsible to provide the physical resources (such as a memory budget) to
the child at the creation time but also during the child's entire lifetime.
Creating children is not for free but the parent has to pay for them. Besides
being the provider of resources, the parent defines all aspects of the
child's execution, and serves as the child's primary point of
contact for seeking acquaintances with other components.

[tikz img/parent_capability]
  Initial relationship between a parent and a new created child.

On the one hand, ownership stands for _responsibility_.
Each component requires physical resources such as the memory used by the
component or in-kernel data structures that represent the component in the
kernel.
The parent is responsible to provide a budget of those physical resources to
the child at the child's creation time but also during the child's entire
lifetime.
As the parent has to assign a fraction of its own physical resources to its
children, it is the parent's natural interest to maintain the balance of
the physical resources split between itself and each of its children.
Besides being the provider of resources, the parent defines all aspects of the
child's execution and serves as the child's primary point of contact for
seeking acquaintances with other components.

Each new component is created as an empty protection domain. It is up to the
parent to populate the protection domain with code and data, and to create a
thread that executes the code within the protection domain. At creation time,
the parent installs a single capability called _parent capability_ into the
new protection domain. The parent capability enables the child to perform RPC
calls to the parent. The child is unaware of anything else that exists in the
Genode system. It does not even know its own identity nor the identity of its
parent. All it can do is issuing calls to its parent using the parent
capability. Figure [img/parent_capability] depicts the situation right after
the creation of a child component. A thread in the parent component created a
new protection domain and a thread residing in the protection domain. It also
installed the parent capability referring to an RPC object provided by the
parent. To provide the RPC object, the parent has to maintain an entrypoint.
For brevity, entrypoints are not depicted in this and the following figures.
Section [Component creation] covers the procedure of creating a component in
detail.

The ownership relation between parent and child implies that each component
has to inherently trust its parent. From a child's perspective, its parent
is as powerful as the kernel. Whereas the child has to trust its parent,
a parent does not necessarily need to trust its children.


Recursive system structure
~~~~~~~~~~~~~~~~~~~~~~~~~~

The parent-child relationship is not limited to a single level. Child
components are free to use their resources to create further children, thereby
forming a tree of components. Figure [img/recursive_structure] shows an
example scenario. The init component creates sub systems according
to its configuration. In the example, it created two children, namely
a GUI and a launcher. The latter allows the user to interactively create
further subsystems. In the example, launcher was used to start an application.

[tikz img/recursive_structure]
  Example of a tree of components. The red arrow represents the ownership
  relation.

At each position in the tree, the parent-child interface is the same. The
position of a component within the tree is just a matter of composition. For
example, by a mere configuration change of init, the application could be
started directly by the init component and would thereby not be subjected to
the launcher.


Services and sessions
~~~~~~~~~~~~~~~~~~~~~

The primary purpose of the parent interface is the establishment
of communication channels between components. Any component can inform
its parent about a service that it provides. In order to provide a service,
a component needs to create an RPC object implementing the so-called
_root interface_. The root interface offers functions for creating
and destroying sessions of the service. Figure [img/announce] shows a
scenario where the GUI component announces its service to the init component.
The announce function takes the service name and the capability for the
service's root interface as arguments. Thereby, the root capability is
delegated from the GUI to init.

[tikz img/announce]
  The GUI component announces its service to its parent using the parent
  interface.

It is up to the parent what to do with the announced information. The
parent may ignore the announcement or remember that the child "GUI" provides
a service "GUI". A component can announce any number of services by
subsequent announce calls.

[tikz img/session_request]
  The application requests a GUI session using the parent interface.

The counterpart of the service announcement is the creation of a session by
a client by issuing a _session_ request to its parent. Figure
[img/session_request] shows the scenario where the application requests a
"GUI" session. Along with the session call, the client specifies the
name of the service and a number of session arguments. The session arguments
enable the client to inform the server about various properties of the
desired session. In the example, the client informs the server that it
is interested in reading user input and that the client's window should be
labeled with the name "browser". As a result of a session request, the
client expects to obtain a capability to an RPC object that implements
the session interface of the requested service. Such a capability is called
_session capability_.

When the parent receives a session request from a child, it is free to take
a policy decision of how to respond to the request. There are several
options.

* The parent may deny the request and thereby prevent the child from using
  a particular service.

* The parent could decide
  to implement the requested service by itself by handing out a session
  capability to a locally implemented RPC object to the child.

* If the parent has received an announcement of the service from another
  child, it may decide to direct the session request to the other child.

* The parent may decide to request a session in the name of its child from
  its own parent.

The figure illustrates the latter option where the
launcher responds to the session request by the application by
issuing a session request from its parent, the init component. Note that by
requesting a session in the name of its child, the launcher is able to
modify the session arguments according to its policy. In the example,
the launcher imposes the use of a different label to the session. When
init receives the session request from the launcher, it is up to the init
to take a policy decision with the same principle options. In fact, each
component that sits in between the client and the server along the branches
of the ownership tree can impose its policy to sessions. The routing of the
session request and the final session arguments as received by the server are
the result of the successive application of all policies along the route.

In the example, init decides to override the "input" argument.
Because the GUI announced its "GUI" service beforehand, init is in possession
of the root capability, which enables it to create and destroy GUI
sessions. It decides to respond to the launcher's session request by
triggering the GUI session creation at the GUI component's root interface.
The GUI component responds to this request with the creation of a new GUI
session and attaches the received session arguments to the new session.
The accumulated session policy is thereby tied to the session's RPC object.
The RPC object is accompanied with its corresponding session capability,
which is delegated along the entire call chain up to the originator of the
session request (Section [Delegation of authority and ownership]). Once the
application's session request returns, the application can interact directly
with the GUI session using the session capability.

[tikz img/session_root]
  Session creation at the server.

The differentiation between session creation and session use aligns two
seemingly conflicting goals with each other, namely efficiency and the
application of the security policies of potentially many components. On the
one hand, all components on the route between client and server are involved
in the creation of the session and thereby can impose their policies on the
session. On the other hand, once established, the direct communication channel
between client and server via the session capability allows for the efficient
interaction between the two components. For the actual use of the session, the
intermediate components are not on the performance-critical path.


Client-server relationship
~~~~~~~~~~~~~~~~~~~~~~~~~~

Whereas the role of a component as a child is dictated by the strict
ownership relation that implies that the child has to ultimately trust
its parent, the role of a component as client or server is more diverse.

In its _role of a client_ that obtained a session capability as result of a
session request from its parent, a component is unaware of the real identity
of the server. It is unable to judge the trustworthiness of the server.
However, it obtained the session from its parent, which the client ultimately
trusts. Whichever session capability was handed out by the parent, the client
is not in the position to question the parent's decision.

However, even though the integrity of the session capability can be taken for
granted, the client does not need to trust the server in the same way as it
trusts its parent. By invoking the capability, the client is in full control
over the information it reveals to the server in the form of RPC arguments.
The confidentiality of its internal state is protected. Furthermore, the
invocation of a capability cannot have side effects to the client's protection
domain other than the retrieval of RPC results. So the integrity of the
client's internal state is protected. However, when invoking a capability, the
clients hands over the flow of execution to the server. The client is blocked
until the server responds to the request. A misbehaving server may never
respond and thereby block the client infinitely. Therefore, with respect to
the liveliness of the client, the client has to trust the server. To empathize
with the role of a component as a client, a capability invocation can be
compared to the call of a function of an opaque 3rd-party library. When
calling such a library function, the caller can never be certain to regain
control. It just expects that a function returns at some point. However, in
contrast to a call of a library function, a capability invocation does not put
the integrity and confidentiality of the client's internal state at risk.

If being in the _role of a server_, a component should generally not trust
its clients. In contrary, from the server's perspective, clients should be
expected to misbehave. This has two practical implications. First, a server is
responsible to validate the arguments of incoming RPC requests. Second, a
server should never make itself dependent on the good will of its clients.
For example, a server should generally not invoke a capability obtained
from one of its clients. A malicious client could have delegated a
capability to a non-responding RPC object, which may block the server
forever when invoked and thereby make the server unavailable for all other
clients. As another example, the server must always be in control
over the physical memory resources used for a sharing-memory interface between
itself and its clients. Otherwise, if a client was in control over the
used memory, it could revoke the memory from the server at any time, possibly
triggering a fault at the server. The establishment of shared memory is
described in detail in Section [Shared memory].
Similarly to the role as client, the internal state of a server is protected
from its clients with respect to integrity and confidentiality.
In contrast to a client, however, the liveliness of a server is protected as
well. A server does never need to wait for any response from a client.
By responding to an RPC request, the server does immediately become ready
to accept the next RPC request without any prior handshake with the client
of the first request.

Regarding the lifetime of a session, the client is not in the immediate
position to dictate the server when to close a session because it has no power
over the server. Instead, the procedure of closing a session follows the same
chain of commands as involved at the session creation. The common parent of
both client and server plays the role of a broker, which is trusted by both
parties. From the client's perspective, closing a session is a request to its
parent and it is up to the policy of the parent to respond to such a request.
From the server's perspective, the request to close a session originates from
its parent, which, as the owner of the server, represents an authority that
must be ultimately obeyed. Otherwise, the parent of a server might take steps
to enforce its will by destructing the server altogether.

; XXX  Description how to resolve mutual distrust and cyclic dependencies.
;      Maybe this topic is better suited for Chapter [Components]?


Resource trading
================

As introduced in Section [Component ownership], child components are created
out of the resources of their respective parent components. This section
describes the underlying mechanism. It first introduces the concept of
RAM sessions in Section [Resource assignment]. Section [Trading of resources]
explains how RAM sessions are used to trade resources between components.
The resource-trading mechanism ultimately allows servers to become resilient
against client-driven resource-exhaustion attacks. However, such servers need
to take special precautions that are explained in Section
[Server-side heap partitioning]. Section [Dynamic resource balancing] presents
a mechanism for the dynamic balancing of resources among cooperative
components.


Resource assignment
~~~~~~~~~~~~~~~~~~~

In general, it is the operating system's job to manage the physical resources
of the machine in a way that enables multiple applications to utilize them in
a safe and efficient manner. The physical resources are foremost the physical
memory, the processing time of the CPUs, and devices.
Traditional operating systems use to provide abstractions of those resource
to applications running on top of the operating system. For example, instead
of exposing the real interface of a device to an application, the OS kernel
provides a representation of the device as a pseudo file in the virtual file
system. An application interacts with a device indirectly by operating on
the respective pseudo file via an device-class-specific API (ioctl
operations). As another example, a traditional OS kernel provides each
application with an arbitrary amount of virtual memory, which may be much
larger than the available physical memory. The application's virtual memory is
backed with physical memory on not before the application actually uses the
memory. The pretension of unlimited memory by the kernel relieves application
developers from considering memory as a limited resource. On the other hand,
this convenient abstraction creates problems that are extremely hard or even
impossible to solve by the OS kernel.

* The amount of physical memory that is at the disposal to back the
  virtual memory is limited. Traditional OS kernels use to employ strategies
  to uphold the illusion of unlimited memory by swapping memory pages to disk.
  However, the swap space on disk is ultimately limited, too. At one point,
  when the physical resources are exhausted, the pretension of unlimited
  memory becomes a leaky abstraction and forces the kernel to take extreme
  decisions such as killing arbitrary processes to free up physical memory.

* Multiple applications including critical applications as well as
  potentially misbehaving applications share one pool of physical resources.
  In the presence of a misbehaving application that exhausts the physical
  memory, all applications are equally put at risk.

* Third, by granting each application the legitimate ability to consume as
  much memory as the application desires, applications cannot be held
  accountable for their consumption of physical memory. The kernel cannot
  distinguish a misbehaving from a well-behaving memory-demanding application.

There are several approaches to relieve those problems. For example, OS
kernels that are optimized for resource utilization may employ heuristics that
take the application behavior into account for parametrizing page-swapping
strategies. Another example is the provisioning of a facility for pinned
memory to application. Such memory is guaranteed to be backed by physical
memory. But such a facility bears the risk of allowing any application to
exhaust physical memory directly. Hence, further heuristics are needed to
limit the amount of pinned memory an application may use. Those counter
measures and heuristics, while making the OS kernel more complex, are mere
attempts to fight symptoms but unable to solve the actual problems caused by
the lack of accounting. The behaviour of the such systems remains largely
indeterministic.

As a further consequence of the abstraction from physical resources, the
kernel has to entail functionality to support the abstraction. For example,
for swapping memory pages to disk, the kernel has to depend on an in-kernel
disk driver. For each application, whether or not it ever touches the disk,
the in-kernel disk driver is part of its trusted computing base.


RAM sessions and balances
-------------------------

Genode does not abstract from physical resources. Instead, it solely
arbitrates the access to such resources and provides means to delegate the
authority over resources between components.
Each low-level physical resource is represented as a dedicated service
provided by the core component at the root of the component tree.
The core component is described in detail in Section
[Core - the root of the component tree].
The following description focuses on memory as the most prominent low-level
resource managed by the operating system.

Physical memory is represented by the RAM service of core. The best way to
describe the idea behind the RAM service is to draw the analogy to a bank.
Each RAM session corresponds to a bank account. Initially, when opening
a new account, there is no balance. However, by having the authority over
an existing bank account with a balance, one can transfer funds from the
existing account to the new account.
Naturally, such a transaction will decrease the balance of the
originating account. Internally at the bank, the transfer does not involve any
physical bank notes. The transaction is merely a change of balances of both
involved bank accounts. In order to pay with physical bank notes, the bank
customer has to withdraw bank notes via an ATM. Such a withdrawal will
naturally decrease the balance on the account. If the account is depleted,
the bank denies the attempt. Analogously to withdrawing
money via an ATM, physical memory can be allocated from a RAM session.
A piece of allocated physical memory is represented by a so-called dataspace
(see Section [Dataspaces] for more details). A RAM dataspace is a container
of physical memory that can be used for storing data.


Subdivision of budgets
----------------------

Similar to a person with a bank account, each component of a Genode system
has a session at core's RAM service.
At boot time, the core component creates an initial RAM session with a balance
set to the amount of available physical memory. This RAM session is designated
for the init component, which is the first and only child of core.
On request by init, core delegates the capability for this initial RAM session
to the init component.

[tikz img/memory_assignment]
  Init assigns a portion of its memory to a child.
  In addition to its own RAM session, init has created a second RAM session
  designated for its child. Init transfers a certain amount
  from its own RAM session to the child's RAM session by invoking its own RAM
  session capability and specifying the beneficiary's RAM-session capability
  as argument. Core will respond to the request by atomically
  adjusting the quotas of both RAM sessions by the specified amount.

For each child component spawned by the init component, init creates a new
RAM session at core. As result from the session creation, it obtains the
capability for the new RAM session. Because it has the authority over both
its own and the child's RAM session, it can transfer a certain amount of RAM
quota from its own account to the child's account. The amount depends on the
configuration of the init component. Thereby, init explicitly splits its
own RAM budget among its child components. Each child created by init can
obtain the capability for its own RAM session via the parent interface and
thereby gains the authority over memory budget that was assigned to it.
Note however, that no child has the authority over init's RAM session nor
the RAM sessions of any siblings. The mechanism for distributing a given
budgets among multiple children works recursively. The children of init
can follow the same procedure to further subdivide their budgets for
spawning grandchildren.


Protection against resource stealing
------------------------------------

[tikz img/resource_stealing]
  Memory-stealing attempt. The client and server components conspire to
  steal memory from the child. The client was created by the child and
  received a portion of the child's memory budget. The client requested
  a session for a service that was eventually routed to the server.
  The client-server relationship allows the client to delegate capabilities
  to the server. Therefore, it is able to delegate its own RAM session
  capability to the server.
  The server, now in possession of the client's and its own RAM session
  capabilities can transfer memory from the client's to its own RAM session.
  After this transaction,
  the child has no way to regain its memory resources because it has no
  authority over the server's RAM session.

A parent that created a child subsystem out of its own memory resources,
expects to regain the spent resources when destructing the subsystem. For
this reason it must not be possible for a child to transfer funds to
another branch of the component tree without the consent of the parent.
Figure [img/resource_stealing] illustrates an example scenario that
violates this expectation.

To prevent such such resource-stealing scenarios, Genode restricts the
transfer between arbitrary RAM sessions. Each RAM session must have a
reference RAM session, which can be defined only once. Transfers are
permitted only between a RAM session and its reference RAM session.


RAM session destruction
-----------------------

The analogy between bank accounts and RAM sessions ends when closing a RAM
session. When a RAM session is closed, core destroys all dataspaces that were
allocated from the RAM session and transfers the RAM session's final budget
to the corresponding reference RAM session.


Trading memory between clients and servers
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

An initial assignment of memory to a child is not always practical because
the memory demand of a given component may be unknown at its construction
time. For example, the memory needed by a GUI server over its lifetime
is not prior known but depends on the number of its clients, the number
of windows on screen, or the amount of pixels that must be held at the
server. In many cases, the memory usage of a server depends on the
behavior of its clients. In traditional operating systems, system services
like a GUI server would allocate memory on behalf of its clients. Even though
the allocation was induced by a client, the server performs the allocation.
The OS kernel remains unaware of the fact that the server solely needs the
allocated memory for serving its client. In the presence of a misbehaving
client that issues an infinite amount of requests to the server where each
request triggers a server-side allocation (for example the creation of a new
window), the kernel will observe the server as a resource hog. Under
resource pressure, it will likely select the server to be punished.
Each server that performs allocations on behalf of its clients is prone to
this kind of attack. Genode solves this problem by letting clients pay for
server-side allocations. Client and server may be arbitrary nodes in
the component tree.


Session quotas
--------------

As described in the previous section, at the creation time of a child, the
parent assigns a part of its own memory quota to the new child. Since the
parent retains the RAM-session capabilities of all its children, it can issue
further quota transfers back and forth between the child's and its own RAM
sessions.
When a child requests a session at the parent interface, it can attach a part
of its quota to the new session by specifying an amount of memory to be
donated to the server as a session argument. This amount is called
_session quota_. The session quota can be used by the server during the
lifetime of the session. It is returned to the client when the session is
closed.

When receiving a session request, the parent has to distinct three different
cases depending on its session-routing decision.

:Parent provides the service:
  If the parent provides the requested service by itself, it first checks
  whether the session quota meets its need for providing the service. If so,
  it transfers the session quota from the requesting child's RAM session to
  its own RAM session. This step may fail if the child offered a session quota
  larger than the available quota in the child's RAM session.

:Server is another child:
  If the parent decides to route the session request to another child, it
  transfers the session quota from the client's RAM session to the server's
  RAM session. Because each of RAM sessions are not related to each other as
  both have the parent's RAM session as reference account, this the transfer
  from the client to the server consists of two steps. First, the parent
  transfers the session quota to its own RAM session. If this step succeeded,
  it transfers the session quota from its own RAM session to the server's RAM
  session. The parent keeps track of the session quota for each session so
  that the quota transfers can be reverted later when closing the session. Not
  before the transfer of the session quota to the server's RAM session
  succeeded, the parent issues the actual session request at the server's root
  interface along with the information about transferred the session quota.

:Delegation to grandparent:
  The parent may decide to delegate the session request to its own parent. In
  this case, the parent will request a session on behalf of its child. The
  grandparent neither knows nor cares about the actual origin of the request
  and will simply decrease the memory quota of the parent. For this reason,
  the parent transfers the session quota from the requesting child to its own
  RAM session before issuing the session request at the grandparent.

This procedure works recursively. Once the server receives the session request
along with the information about the provided session quota, it can use this
information to decide whether or not to provide the session under these
resource conditions. It can also use the information to tailor the quality of
the service according to the provided session quota. For example, a larger
session quota might enable the server to use larger caches or communication
buffers for the client's session.


Session upgrades
----------------

If the initial session quota turns out to be too scarce during
the lifetime of a session, the client may upgrade the session quota of an
existing session via issuing an upgrade request to is parent along with
the targeted session capability and the additional session quota. The
upgrade works analogously to the session creation. The server will
receive the information about the upgrade via the root interface of the
service.


Closing sessions
----------------

If a child issues a session-close request to its parent, the parent determines
routes the close request to the corresponding server, which, depending on the
route of the original session request, may be locally implemented, provided by
another child, or provided by the grandparent. Once the server receives the
session-close request, it is responsible to release all resources that were
allocated from the session quota. After the server reverts all
session-specific allocations, the server's RAM session is expected to have at
least as much available budget as the session quota of the to-be-closed
session. So the session quota can be transferred back to the client.

However, an misbehaving server may fail to release those resources by malice
or caused by a bug. If the misbehaving service was locally provided by the
parent, it has the full authority to not hand back the session quota to its
child. If the misbehaving service was provided by the grandparent, the parent
(and its whole subsystem) has to subordinate. If, however, the service was
provided by another child and the child refuses to release resources, the
parent's attempt to withdraw the session quota from the server's RAM session
will fail.
It is up to the policy of the parent to handle such a failure either by
punishing the server (e.g., killing the component) or by granting more of its
own quota. Generally, misbehavior is against the server's own interests. A
server's best interest is to obey the parent's close request to avoid
intervention.


Dynamic resource balancing
~~~~~~~~~~~~~~~~~~~~~~~~~~

As described in Section [Resource assignment], parent components explicitly
assign physical resource budgets to its children. Once assigned, the assigned
budget is at the disposal of the respective child subsystem until the
subsystem gets destroyed by the parent.

However, not all components have well-defined resource demands. For example, a
block cache should utilize as much memory as possible unless the memory is
needed by another component. The assignment of fixed amount of memory to such
a block cache cannot accommodate changes of workloads over the potentially
long lifetime of the component. If dimensioned too small, there may be a lot
of slack memory remaining unutilized. If dimensioned too large, the block
cache would prevent other and possibly more important components to use the
memory. A better alternative is to enable a component to adapt its resource
use to the resource constraints of its parent. The parent interface supports
this alternative with a protocol for the dynamic balancing of resources.

The resource-balancing protocol uses a combination of synchronous
remote procedure calls and asynchronous notifications. Both mechanism
are described in Section [Inter-component communication]. The child
uses remote procedure calls to talk to its parent whereas the parent
uses asynchronous notification to signal state changes to the child.
The protocol consists of two parts, which are complementary.


Resource requests
-----------------

By issuing a resource request to it parent, a child applies for an upgrade
of its resources. The request takes the amount of desired resources as
argument. A child would issue such a request if it detects scarceness of
resources. A resource request returns immediately regardless of whether
additional resources had been granted or not. The child may proceed working
under the low resource conditions or it may block for a resource-available
signal from its parent.
The parent may respond to this request in different ways. It
may just ignore the request, possibly stalling the child. Alternatively,
it may immediately transfer additional quota to the child's RAM session.
Or it may take further actions to free up resources to accommodate the child.
Those actions may involve long-taking operations such as the destruction
of subsystems or the further propagation of resource request towards the
root of the component tree.
Once the parent has freed up enough resources to accommodate the child's
request, it transfers the new resources to the child's RAM session and
notifies the child by sending a resource-available signal.


Yield requests
--------------

The second part of the protocol enables the parent to express its wish for
regaining resources. The parent notifies the child about this condition by
sending a yield signal to the child. On the reception of such a signal, the
child picks up the so-called yield request at the parent using an remote
procedure call. The yield request contains the amount of resources, the parent
wishes to regain. It is up to the child to comply with a yield request or not.
Some subsystems have meaningful ways to respond to yield requests. For
example, an in-memory block cache could write back the cached information and
release the memory consumed by the cache. Once the child has succeeded in
freeing up resource, it reports to parent by issuing a so-called yield
response via an remote procedure call to the parent. The parent may respond to
a yield response by withdrawing resources from the child's RAM session.

| XXX
|
| Sequence diagrams might be nice to illustrate the interplay between
| parent and child for resource requests and yield requests.


Core - the root of the component tree
=====================================

Core is the initial component and thereby represents the root of the
component tree. Technically, it is the first user-level program started
by the kernel.
It has access to the raw physical resources such as memory, CPUs,
memory-mapped devices, interrupts, I/O ports, and boot modules.
Core exposes those low-level resources as services so that they
can be used by other components. For each type of resource, there exists
a service in core. For example, memory resources are represented by the
RAM service, interrupts are represented by the IRQ service, and CPUs are
represented by the CPU service. In order to access a resource, a component
has to establish a session to the corresponding service. Thereby the
access to physical resources is subjected to the routing of session requests
as explained in Section [Services and sessions]. Moreover, the
resource-trading concept described in Section
[Trading memory between clients and servers] applies to core services in
the same way as for any other service.

In addition to making hardware resources available as services, core
provides all prerequisites to bootstrap the component tree.
These prerequisites comprise services for creating protection domains,
for managing address-space layouts, and for creating object identities.

Core is almost free from policy. There are no configuration options.
The only policy of core is the startup of the init process, to which core
grants all available resources. Init, in turn, uses those resources to
spawn further components according to a configuration.

Section [Dataspaces] introduces dataspaces as containers of memory or
memory-like resources. Dataspaces form the foundation for most of the core
services described in the subsequent sections.


Dataspaces
~~~~~~~~~~

A dataspace is an RPC object that represents a contiguous physical
address-space region with an arbitrary size. Its base address and size are
subjected to the granularity of physical pages as dictated by the
memory-management unit (MMU) hardware. Typically the granularity is 4 KiB.

Dataspaces are created and managed via core's services.
Because each dataspace is a distinct RPC object, the authority over the
contained physical address range is represented by a capability and can
thereby be delegated between components.
Each component in possession of a dataspace capability can make the
dataspace content visible in its local address space (using core's RM service
described in Section [Address-space management (RM)]). Hence, by the means of
delegating dataspace capabilities, components can establish shared memory.

The system on top of core never deals with physical memory pages but
uses dataspaces as a uniform abstraction for memory, memory-mapped I/O
regions, and boot modules.


Physical memory allocation (RAM)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

A RAM session is a quota-bounded allocator physical memory.
At session-creation time, its quota is zero.
To make the RAM session functional, it must first receive quota from
another already existing RAM session, which is called the _reference account_.
Once the reference account is defined, quota can be transferred back and
forth between the reference account and the new RAM session.

Provided that the RAM session is equipped with sufficient quota, the RAM
client can allocate RAM dataspaces from the RAM session. The size of
each RAM dataspace is defined by the client at the allocation time.
The location of the dataspace in physical memory is defined by core.

Each RAM dataspace is physically
contiguous and can thereby be used as DMA buffer by a user-level device
driver. In order to set up DMA transactions, such a device driver can request
the physical address of a RAM dataspace by invoking the dataspace capability.

Closing a RAM session destroys all dataspaces allocated from
the RAM session and restores the original quota. This implies that these
dataspaces disappear in all components. The quota of a closed RAM session
is transferred to the reference account.

For book keeping and the creation of dataspace RPC object within core, the RAM
service requires memory. This memory is allocation from the session quota as
supplied by the RAM client. Note that this session quota is not related to the
quota managed by the RAM session.


Access to boot modules (ROM)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Boot modules are chunks of data loaded by the boot loader into memory.
Examples for such modules are the ELF images of the core component, the
init component, the components created by init, and the configuration of the
init component.
Core makes each boot modules available as a ROM session. Because boot modules
are read-only memory, they are generally called ROM modules.
On session construction, the client specifies the name of the ROM module
as session argument.
Once created, the ROM session allows its client to obtain a ROM dataspace
capability. Using this capability, the client can make the ROM module
visible within its local address space.


Protection domains (PD)
~~~~~~~~~~~~~~~~~~~~~~~

A protection domain (PD) corresponds to a unit of protection within the Genode
system. Typically, there is a one-to-one relationship between a component and
a PD. At the hardware-level the CPU isolates different protection domains via
a memory-management unit. Each domain is represented by a different page
directory, or an address-space ID. A PD session is a representation of the
used hardware-based protection facility.

In addition to representing the unit of memory protection, a PD comprises a
capability space as introduced in
Section [Capability spaces, object identities, and RPC objects].
Initially, the PD's capability space is empty. However, the PD client can
populate the capability space with a single capability, which is the
parent capability of the component within the PD. The assignment of the
parent capability is done at the creation time of the component by its
parent.

A PD on its own is not useful unless is becomes associated with an
address-space layout (RM session) and at least one thread of execution
(CPU session). Section [Component creation] explains how those sessions
can be combined as basic building blocks for creating a component.


Address-space management (RM)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

An region manager (RM) session represents the layout of a virtual address
space. The size of the virtual address space can be defined via session
arguments at the session-creation time.


Populating an address space
---------------------------

The concept behind RM sessions is a generalization of the MMU's page-table
mechanism. Analogously to how a page table is populated with physical page
frames, an RM session is populated with dataspaces.
Under the hood, core uses the MMU's page-table mechanism as a cache for RM
sessions.
An RM client in possession of a dataspace capability is
able to _attach_ the dataspace to the RM session.
Thereby the content of the dataspace becomes visible within the RM session's
virtual address space.
When attaching a dataspace to an RM session, core selects an appropriate
virtual address range that is not yet populated with dataspaces.
Alternatively, the client can specify a designated virtual address.
It also has the option to attach a mere window of the dataspace to the RM
session. Furthermore, the client can specify whether the content of the
dataspace should be executable or not.

The counter part of the _attach_ operation, the RM client is able to remove
dataspaces from its RM session by specifying a virtual address. Under the
hood, this operations flushes the MMU mappings of the corresponding virtual
address range so that the dataspace content becomes invisible.

Note that a single dataspace may be attached to any number of RM sessions.
A dataspace may also be attached multiple times to one RM session. In this
case, each attach operation populates a distinct region of the virtual
address space.


Assigning threads to an address space
-------------------------------------

As for a PD session, an RM session is not useful on its own. To enable the
use of the RM-session's address-space layout for a component, it must first be
associated with a thread of execution. An RM client can establish this
association with the RM session's _add-client_ operation, which takes a
thread capability (obtained from a CPU session) as argument.
Once associated, core uses the address-space layout of the RM session to
resolve page faults caused by the thread.


Realizing managed dataspaces
----------------------------

The entirety of an RM session can be used as a dataspace. Such a
_managed dataspace_ is not backed by a range of physical addresses but
by the range of virtual addresses of its underlying RM session.
This makes RM sessions a generalization of nested page tables.
An RM client can obtain a dataspace capability for a given RM session
and use this dataspace capability in the same way as any other dataspace
capability, i.e., attaching it to its local address space, or delegating
it to other components.

Managed dataspaces are used in two ways. First, they allow for the manual
management of portions of a component's virtual address space. For example,
the so-called thread-context area is a dedicated virtual-address ranged
preserved for stacks. Between the stacks, the virtual address space must
remain empty so that stack overflows won't silently corrupt data. This
is achieved by creating a RM session that represents the complete
thread-context area. This RM session is attached as a dataspace to the
component's virtual address space. When creating a new thread with its
corresponding stack, the thread's stack is not directly attached to the
component's RM session but to the context area's RM session. Another
example is the virtual-address range managed by a dynamic linker to load
shared libraries into.

The second use of managed dataspaces is the provision of on-demand-paged
dataspaces. A server may hand out dataspace capabilities that are backed by RM
sessions to its clients. Once the client has attached this dataspace to its
address space and touches the content, the client triggers a page fault. Core
responds to this page fault by blocking the client thread and delivering a
notification to the RM client of the managed dataspace (the server) along with
the information about the fault address within the RM session. The server can
resolve this condition by attaching a dataspace with real backing store at the
fault address, which prompts core to resume the execution of the faulted
thread.

| XXX Managed dataspaces could be described in more detail, in particular
| the on-demand paging protocol. On the other hand, the on-demand paging
| facility is not very important in practice.


Processing-time allocation (CPU)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

A CPU session is an allocator for processing time that allows for the creation,
the control, and the destruction of threads of execution.
At session-construction time, the affinity of a CPU session with CPU cores can
be defined via session arguments.

Once created, the session can be used to create, control, and kill threads.
Each thread created via a CPU session is represented by a thread capability.
The thread capability is used for associating the thread with its address
space layout (RM session) as well as for subsequent thread-control operations.
The most prominent thread-control operation is the _start_ of the thread,
which takes the thread's initial stack pointer and instruction pointer as
arguments.

During the lifetime of a thread, the CPU client can retrieve and manipulate
the _state_ of the thread. This includes the register state as well as the
execution state (whether the thread is paused or running). Those operations
are primarily designated for realizing user-level debuggers.

To aid the graceful destruction of threads, the CPU client can issue a
_cancel-blocking_ operation, which causes the specified thread to cancel a
current blocking operation such as waiting for an RPC response
or the attempt to acquire a contended a lock.


Object-identity allocation (CAP)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Genode regards object identities as a physical resource because each object
identity is represented as a kernel object. Core's CAP service allows for the
creation and destructions of new object identities. For each RPC object
associated to an RPC entrypoint, the entrypoint requests the creation of
a new object identity from a CAP session and associates the RPC object with
the capability allocated from the CAP service.

The interplay between RPC objects, the RPC entrpoint, and core's CAP service
is described in more depth in
Section [Synchronous remote procedure calls (RPC)].


Access to device resources (IO_MEM, IO_PORT, IRQ)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Core's IO_MEM, IO_PORT, and IRQ services enable the realization of user-level
device drivers as Genode components.


Memory mapped I/O (IO_MEM)
--------------------------

An IO_MEM session provides a dataspace representation for a non-memory part of
the physical address space such as memory-mapped I/O regions or BIOS areas.
In contrast to a memory block that is used for storing information, of which
the physical location in memory is of no matter, a non-memory object has
special semantics attached to its location within the physical address space.
Its location is either fixed (by standard) or can be determined at runtime,
for example by scanning the PCI bus for PCI resources. If the physical
location of such a non-memory object is known, an IO_MEM session can be
created by specifying the physical base address, the size, and the
write-combining policy of the memory-mapped resource as session arguments.
Once an IO_MEM session is created, the IO_MEM client can request a dataspace
containing the specified physical address range.

Core hands out each physical address range only once. Session requests for
ranges that intersect with physical memory are denied. Even though the
granularity of memory protection is limited by the MMU page size, the IO_MEM
service accepts the specification of the physical base address and size at the
granularity of byes. The rationale behind this contradiction is the
unfortunate existence of platforms that host memory-mapped resources of
unrelated devices on the same physical page. When driving such devices from
different components, each of those components requires access to its
corresponding device. So the same physical page must be handed out to multiple
components. Of course, those components must be trusted to not touch any
portion of the page that is unrelated to its own device.


Port I/O (IO_PORT)
------------------

For platforms that rely on I/O ports for device access, core's IO_PORT service
enables fine-grained assignment of port ranges to individual components.
Each IO_PORT session corresponds to the exclusive access right to a port range
specified as session arguments. Core creates the new IO_PORT session only if
the specified port range does not overlap with an already existing session.
This ensures that each I/O port is driven by only one IO_PORT client at a
time.
The IO_PORT session interface resembles the physical I/O port access
instructions.
Reading from an I/O port can be performed via an 8bit, 16bit, or 32bit access.
Vice versa, there exist operations for writing to an I/O port via an 8bit,
16bit, or 32bit access.
The read and write operations take absolute port addresses as arguments.
Core performs the I/O port operating only if the specified port address lies
within the port range of the session.


Reception of device interrupts (IRQ)
------------------------------------

Core's IRQ service provides enables device-drivers components to respond to
device interrupts. Each IRQ session corresponds to an interrupt.
The physical interrupt number is specified as session argument.
Each physical interrupt number can be specified to only one session.
The IRQ session
interface provides an operation to wait for the next interrupt.
Only while the IRQ client is waiting for an interrupt, core unmasks the
interrupt at the interrupt controller.
Once the interrupt occurs, core wakes up the IRQ client and masks the
interrupt at the interrupt controller until the driver has completed the IRQ
handing and waits for the next interrupt.

| XXX A sequence diagram showing the interplay of the device, IRQ controller,
| core, and the user-level device driver might be helpful.


Logging (LOG)
~~~~~~~~~~~~~

The LOG service is used by the lowest-level system components such as the init
process for printing diagnostic output.
Each LOG session takes a label as session argument, which is used to prefix
the output of this session.
This enables developers to distinguish the output of different components with
each component having a unique label.
The LOG client transfers the to-be-printed characters as payload of plain RPC
messages as the simplest possible communication mechanism between the LOG
client and core's LOG service.


Asynchonous notifications (SIGNAL)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Core's SIGNAL service plays the role of a broker of asynchronous notifications
on kernels that lack the semantics of Genode's signalling API. The service
is not used directly by components at the framework's API level but is merely
an implementation artifact.

| XXX The role of the SIGNAL service could be substantiated in
| Chapter [Under the hood].


Event tracing (TRACE)
~~~~~~~~~~~~~~~~~~~~~

| XXX This service is not fundamental to the architecture. To which degree
| should we introduce it here?


Component creation
==================

| TODO


Inter-component communication
=============================

| TODO

Synchronous remote procedure calls (RPC)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Asynchronous notifications
~~~~~~~~~~~~~~~~~~~~~~~~~~

Shared memory
~~~~~~~~~~~~~

Synchronous bulk transfer
~~~~~~~~~~~~~~~~~~~~~~~~~

Asynchronous bulk transfer - packet streams
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


