Components
##########

The architecture introduced in Chapter [Architecture] clears the way to
compose sophisticated systems out of many building blocks. Each building
block is represented by an individual component that resides in a dedicated
protection domain and interacts with other components in a well-defined manner.
Those components do not merely represent applications but all typical
operating-system functionalities.

Components can come in a large variety of shape and form.
Compared to a monolithic operating-system kernel, a component-based operating
system challenges the system designed by enlarging the design space by the
decision of the functional scope of each component and thereby the granularity
of componentization. This decision depends on several factors:

:Security:
  The smaller a component, the lower the risk for bugs and vulnerabilities.
  The more rigid a component's interfaces, the smaller its attack surface
  becomes.
  Hence, the security of a complex system function can potentially be vastly
  improved by splitting it into a low-complexity component that encapsulates
  the security-critical part and a high-complexity component that is
  uncritical for security.

:Performance:
  The split of functionality into multiple components introduces
  inter-component communication and thereby context-switch overhead.
  If a functionality is known to be critical for performance, such a split
  should be clearly motivated by a benefit for security.

:Reusability:
  Componentization can be pursued for improved reusability while sometimes
  disregarding performance considerations. However, reusability can also be achieved by
  moving functionality into libraries that can be easily reused by linking
  them directly against library-using components. By using a dynamic linker,
  the linking can even happen at run time, which yields the same flexibility
  as the use of multiple distinct components. Therefore, the split of
  functionality into multiple components for the sole sake of modularization
  is to be questioned.

The Sections [Device drivers], [Protocol stacks], [Resource multiplexers], and
[Runtime environments] aid the navigation within the componentization design
space by discussing the different roles a component can play within a Genode
system.
Those can be be the role of a device driver, protocol stack, resource
multiplexer, runtime environment, and that of an application. By
distinguishing those roles, it becomes possible to assess the possible
security implications of each individual component.

The versatility of a component-based systems does not come from the
existence of a many components alone. Even more important is the
composability of components. Components can be combined only if their
interfaces match. To maximize composability, the number of interfaces
throughout the system should be as low as possible, and all interfaces
should be largely orthogonal to each other.
Section [Common session interfaces] reviews Genode's common session
interfaces.

Components can be used in different ways depending on their position
within the component tree. Section [Component compositions] discusses
the most prominent options of composing components.


Device drivers
==============

A device driver translates a device interface to a Genode session interface.
Figure [img/device_driver] illustrates the typical role of a device driver.

[tikz img/device_driver]
  A network device driver provides a NIC service to a single client and uses
  core's IO-MEM and IRQ services to interact with the physical network adaptor.

; Raw device access

The device interface is defined by the device vendor and typically
comprises the driving of state machines of the device, the
notification of device-related events via interrupts, and a means to
transfer data from and to the device.
A device-driver component accesses the device interface via sessions to the
core services IO_MEM, IO_PORT, and IRQ as described in
Section [Access to device resources (IO_MEM, IO_PORT, IRQ)].

; Translator, not multiplexer

In general, a physical device cannot safely be driven by multiple users at the
same time. If multiple users accessed one device concurrently, the device
state would eventually become inconsistent.
A device driver should not attempt to multiplex device.
Instead, to keep its complexity low, it should act as a server that serves
only a single client per physical device.
Whereas a device driver for a simple device usually accepts only one client,
a device driver for a complex device with multiple sub devices (such as
an USB driver) may hand out each sub device to a different client.

; Void of built-in policy but enforces policy

A device driver should be largely void of built-in policy. If it merely
translates the interface of a single device to a session interface, there is
not much room for policy anyway. If, however, a device driver hands out
multiple sub devices to different clients, the assignment of sub devices
to clients must be subjected to a policy. In this case, the device driver
should obtain this policy information from its configuration as provided by
the driver's parent component.


Platform driver
~~~~~~~~~~~~~~~

There are three problems that are fundamentally important for a running an
operating system on modern hardware but that lie outside the scope of a
ordinary device driver because they are affect the platform as a whole rather
than a single device. Those problems are the enumeration of devices, the
discovery of interrupt routing, and the initial setup of the platform.


Device enumeration
------------------

Modern hardware platforms are rather complex and vary a lot. For example,
the devices attached to the PCI bus of a PC are usually not known at the
build time of the system but need to be discovered at run time. Technically,
each individual device driver could probe its respective device at the
PCI bus. But in the presence of multiple drivers, this approach would not
work. First, the configuration interface of the PCI bus is a device itself.
The concurrent access to the PCI configuration interface by multiple drivers
would ultimately yield undefined behaviour. Second, if each driver spoke
directly to the PCI configuration interface, each driver would need to
carry with it the functionality to interact with PCI.


Interrupt routing
-----------------

On PC platforms with multiple processors, the use of legacy interrupts as
provided by the Intel 8259 programmable interrupt controller (PIC) is not
suitable because, among several other reasons, there is no way to express the
assignment of interrupts to CPUs. To overcome the limitations of the PIC,
Intel introduced the Advanced Programmable Interrupt Controller (APIC). The
APIC, however, comes with a different name space for interrupt numbers, which
creates an inconsistency between the numbers provided by the PCI configuration
(interrupt lines) and interrupt numbers as understood by the APIC. The
assignment of legacy interrupts to APIC interrupts is provided by tables
provided by the Advanced Configuration and Power Interface (ACPI).
Consequently, in order to support multi-processor PC platforms, the operating
system needs to interpret those tables. Within a component-based system, we
need to answer the question of which component is responsible to interpret the
ACPI tables and how this information is applied to the individual device
drivers.


Initial hardware setup
----------------------

In embedded systems, the interaction of the SoC (system on chip) with its surrounding
peripheral hardware is often not fixed in hardware but rather a
configuration issue. For example, the power supply and clocks of certain
peripherals may be enabled by speaking an I2C protocol with a separate
power-management chip. Also, the direction and polarity of the general-purpose
I/O pins depends largely on the way how the SoC is used. Naturally, such
hardware setup steps could be performed by the kernel. But this would require
the kernel to become aware of potentially complex platform intrinsics.


Central platform driver
-----------------------

The natural solution to these problems is the introduction of a so-called
platform driver, which encapsulates the peculiarities outlined above. On PC
platforms, the role of the platform driver is played by the ACPI driver. The
ACPI driver provides an interface to the PCI bus in the form of a PCI service.
Device drivers obtain the information about PCI devices by creating a PCI
session at the ACPI driver. Furthermore, the ACPI driver provides an IRQ
service that transparently applies the interrupt routing based on the
information provided by the ACPI tables. Furthermore, the ACPI driver provides
the means to allocate DMA buffers, which is further explained in Section
[Direct memory access (DMA) transactions].

On ARM platforms, the corresponding component is named platform driver
and provides a so-called platform service. Because of the large variety of
ARM-based SoCs, the session interface for this service differs from platform
to platform.


Interrupt handling
~~~~~~~~~~~~~~~~~~

Most device drivers need to respond to sporadic events produced by the
device and propagated to the CPU as interrupts. In Genode, a device-driver
component obtains device interrupts via core's IRQ service introduced in
Section [Access to device resources (IO_MEM, IO_PORT, IRQ)]. On PC platforms,
device driver usually do not use core's IRQ service directly but rather
use the IRQ service provided by the platform driver
(Section [Platform driver]).

; XXX sequence diagram of handling an interrupt?


Direct memory access (DMA) transactions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Devices that need to transfer large amounts of data usually support a means
to issue data transfers from and to the system's physical memory
without the active participation of the CPU. Such transfers are called
_direct memory access (DMA) transactions_. DMA transactions relieve the CPU
from actively copying data between device registers and memory, optimize
the throughput of the system bus by the effective use of burst transfers, and
may even be used to establish direct data paths between devices.
However, the benefits of DMA transaction come at the risk of corrupting
the physical memory by misguided DMA transactions.
Because those DMA-capable devices can issue bus requests
targeting the physical memory directly and not involving the CPU altogether, such requests
are naturally not subjected by the virtual-memory mechanism implemented in the
CPU in the form of a memory-management unit (MMU).
Figure [img/no_iommu] illustrates the problem. From the device's point of
view, there is just physical memory.
Hence, if a driver sets up a DMA transaction, e.g., if a disk driver reads a
block from the disk, the driver programs the memory-mapped registers of the
device with the address and size of a physical-memory buffer where it expects
to receive the data.
If the driver lives in a user-level component, as is the case for a
Genode-based system, it still needs to know the physical address of the DMA
buffer to program the device correctly.
Unfortunately, there is nothing to prevent the driver from specifying any
physical address to the device.
Consequently, a malicious driver could misuse the device to read and
manipulate all parts of the physical memory, including the kernel.
Consequently, device drivers and devices should ideally be trustworthy.
However, there are several situations where this is ultimately not
the case.

[tikz img/no_iommu 100%]
  The MMU restricts the access of physical memory pages by different
  components according to their virtual address spaces.
  However, direct memory accesses issued by the disk controller are not
  subjected to the MMU. The disk controller can access the entirety of the
  physical memory present in the system.


Direct device assignment to virtual machines
--------------------------------------------

When hosting virtual machines as Genode components, the direct assignment of
a physical device such as a USB controller, a GPU, or a dedicated network
card to the guest OS running in the virtual machine can be
useful in two ways. First, if the guest OS is the sole user of the device,
the direct assignment of the device maximizes the I/O performance of the
guest OS using the device. Second, the guest OS may be equipped with a
proprietary device driver that is not present as a Genode component otherwise.
In this case, the guest OS may be used as a runtime executing the device
driver and providing a driver interface to the Genode world. In both cases
the guest OS should not be considered as trustworthy.
In contrary, it bears the risk to subvert the isolation between components.
A misbehaving guest OS could issue DMA requests referring
to the physical memory used by other components and even the kernel and
thereby break out of its virtual machine.


Firmware-driven attacks
-----------------------

Modern peripherals such as wireless LAN adaptors, network cards, or GPUs
employ firmware executed on the peripheral device. This firmware is executed
on a microcontroller on the device, and is thereby not subjected to the
policy of the normal operating system. Such firmware may either be built-in
by the device vendor, or is loaded by the device driver at initialization
time of the device. In both cases, the firmware tends to be a black box
that remains obscure except for the device vendor. Hence, hidden functions
or vulnerabilities might be present in it. By the means of DMA transactions, such
firmware has unlimited access on the system. For example, a back door
implemented in the firmware of a network adaptor could look for
special network packets to activate and control arbitrary spyware functions.
Because malware embedded in the firmware of the device can neither be detected
nor controlled by the operating system, both monolithic and microkernel-based
operating systems are powerless against such attacks.


Bus-level attack
----------------

The previous examples misused a DMA-capable device as a proxy to drive an
attack. However, the system bus can be attacked directly with no hardware
tinkering needed. There are ready-to-exploit interfaces that featured on most
PC systems. For example, most laptops come with PCMCIA / ExpressCard slots,
which allow expansion cards to access the system bus. Furthermore, serial bus
interfaces, i.e., IEEE 1394 (Firewire) enable connected devices to indirectly
access the system bus via the peripheral bus controller. If the bus controller
allows the device to issue direct system bus requests by default, any connected
device becomes able to gain control over the whole system. This vulnerability
has been present on a wide range of commodity computers.


DMA transactions in component-based systems
-------------------------------------------

Direct memory access (DMA) of devices looks like the Achilles
heel of component-based operating systems. The most compelling argument in
favour of componentization is that by encapsulating each system component
within a dedicated user-level address space, the system as a whole becomes more
robust and secure compared to a monolithic operating-system kernel. In the
event that one component fails due to a bug or an attack, other components
remain unaffected. The prime example for such buggy components are, however, device
drivers. By empirical evidence, those remain the most prominent trouble makers
in today's operating systems, which suggests that the DMA loophole renders
the approach of component-based systems largely ineffective.
However, there are three counter arguments to this observation.

[tikz img/iommu]
  An IOMMU arbitrates and virtualizes DMA accesses issued by a device to the
  RAM. Only if a valid IOMMU mapping exists for a given DMA access, the memory
  access is performed.

First, by encapsulating each driver in a dedicated address space,
classes of bugs that are unrelated to DMA remain confined in the
driver component. In practice most driver-related problems stem from issues like
memory leaks, synchronization problems, deadlocks, flawed driver logic, wrong
state machines, or incorrect device-initialization sequences. For those classes
of problems, the benefits of isolating the driver in a dedicated component
still applies.

Second, executing a driver largely isolated from other operating-system code
minimizes the attack surface onto the driver. If the driver interface is
rigidly small and well-defined, it is hard to compromise the driver by
exploiting its interface.

Third, modern PC hardware has closed the DMA loophole by incorporating
so-called IOMMUs into the system. As depicted in Figure [img/iommu], the IOMMU
sits between the physical and the system bus where the devices are attached to.
So each DMA request has to pass the IOMMU, which is not only able to arbitrate
the access of DMA requests to the RAM but also able to virtualize the address
space per device. Similar to how a MMU confines each process running on the
CPU within a distinct virtual address space, the IOMMU is able to confine each
device within a dedicated virtual address space. To tell the different devices
apart, the IOMMU uses the PCI device's bus-device-function triplet as unique
identification.

With an IOMMU in place, the operating system can effectively limit the scope
of actions the given device can execute on the system. I.e., by restricting
all accesses originating from a particular PCI device to the DMA buffers used
for the communication, the operating system becomes able to detect and prevent
any unintended bus accesses initiated by the device.

When executed on the NOVA kernel, Genode subjects all DMA transactions to the
IOMMU, if present. Section [IOMMU support] discusses the use of IOMMUs in
more depth.


Protocol stacks
===============

[tikz img/protocol_stack]
  Example of a protocol stack. The terminal provides the translation between
  the terminal-session interface (on the right) and the driver interfaces
  (on the left).

A protocol stack _translates_ one session interface to another (or the same)
session interface. For example, a terminal component may provide a command-line
application with a service for obtaining textual user input and
printing text.
To implement this service, the terminal uses an input session and a
framebuffer session. Figure [img/protocol_stack] depicts the relationship
between the terminal, its client application, and the used drivers.
For realizing the output of a stream of characters on
screen, it implements a parser for escape sequences, maintains a state machine
for the virtual terminal, and renders the pixel representation of characters
onto the framebuffer. For the provisioning of textual user input, it responds
to key presses reported by the input session, maintains the state of modifier
keys, and applies a keyboard layout to the stream of incoming events.
When viewed from the outside the component, the terminal translates a terminal
session to a framebuffer session and an input session.

Similar to device drivers, a protocol stack typically serves a single client.
In contrast to device drivers, however, protocol stacks are not bound to
physical devices. Therefore, a protocol stack can be instantiated any number
of times. For example, if multiple terminals are needed, one terminal
component could be instantiated per terminal. Because each terminal has an
independent instance of the protocol stack, a bug in the protocol stack of one
terminal does affect any other terminal. However complex the implementation of
the protocol stack may be, it is not prone to leaking information to another
terminal because it is connected to a single client only. The leakage of
information is constrained to interfaces used by the individual instance.
Hence, protocol stacks appear often as the most suitable category of
components to host highly complex untrusted code if needed.

Note that the example above cannot be generalized. There are protocol stacks
that are critical for the confidentiality of information. For example, an
in-band encryption component may translate plain-text network traffic to
encrypted network traffic designated to be transported over a public network.
Even though the component is a protocol stack, it may still be prone to
leaking unencrypted information to the public network.

Whereas protocol stacks are not necessarily critical for integrity and
confidentiality, they are almost universally critical for availability.


Resource multiplexers
=====================

[tikz img/resource_multiplexer]
  A GUI server multiplexes the physical framebuffer and input devices among
  multiple applications.

A resource multiplexer transforms one resource into a number of virtual
resources. A resource is typically a session to a device driver. For
example, a NIC-switch component may use one NIC session to a NIC driver
as uplink and, in turn, provide a NIC service where each session represents
a virtual NIC. Another example is a GUI server as depicted in Figure
[img/resource_multiplexer], which enables multiple applications to share
the same physical framebuffer and input devices by presenting each
client in a window or a virtual console.

In contrast to a typical device driver or protocol stack that serves only a
single client, a resource multiplexer is shared by potentially many clients.
In the presence of untrusted clients besides security-critical clients,
a resource multiplexer ultimately becomes a so-called _multi-level_ component.
This term denotes that the component is cross-cutting the security levels
of all its clients. This has the following ramifications.

:Covert channels:
  Because the component is a shared resource that is accessed by clients
  of different security levels, it must maintain the strict isolation
  between its clients unless explicitly configured otherwise. Hence, the
  component's client interface as well as the internal structure must be
  designed to prevent the leakage of information across clients. I.e.,
  two clients must never share the same namespace of server-side objects
  if such a namespace can be modified by the clients. For example, a window
  server that hands out global window IDs to its clients is prone to
  unintended information leakage because one client could observe the
  allocation of window IDs by another client. The ID allocation could be
  misused as a covert channel that circumvents security policies.
  In the same line, a resource multiplexer is prone to timing channels if
  the operations provided via its client interface depends on the behavior
  of other clients. For this reason, blocking RPC calls should be avoided
  because the duration of a blocking operations may reveal information about
  the internal state such as the presence of other clients of the resource
  multiplexer.

:Complexity is dangerous:
  As a resource multiplexer is shared by clients of different security
  levels, the same considerations apply as for the OS kernel: High complexity
  poses a high risk for bugs. Such bugs may, in turn, result in the
  unintended flow of information between clients or spoil the quality of
  service for all clients. Hence, resource multiplexers must be as low complex
  as possible.

:Denial of service:
  The exposure of a resource multiplexer to untrusted and even malicious
  clients makes it a potential target for denial-of-service attacks.
  Some operations provided by the resource multiplexer may require the
  allocation of memory. For example, a GUI server may need to memory for
  the book keeping of each window created its clients.
  If the resource multiplexer performed such allocations from its own
  memory budget, a malicious client could trigger the exhaustion of
  server-side memory by creating new windows in an infinite loop.
  To mitigate this category of problems, a resource multiplexer should perform
  memory allocations exclusively from client-provided resources, i.e., using
  the session quota as provided by each client at the session-creation time.
  Section [Resource trading] describes Genode's resource-trading mechanism
  in detail.

:Avoiding built-in policies:
  A resource multiplexer can be understood as a microkernel for a higher-level
  resource. Whereas a microkernel multiplexes or arbitrates the CPU and
  memory between multiple components, a resource multiplexer does the same
  for sessions.
  Hence, the principles for constructing microkernels equally apply for
  resource multiplexers.
  In the line of those principles, a resource multiplexer should ideally
  implement sole mechanisms but should be void of built-in policy.

:Enforcement of policy:
  Instead of providing a built-in policy, a resource multiplexer obtains
  policy information from its configuration as supplied by its parent.
  The resource multiplexer must enforce the given policy. Otherwise, the
  security policy defined by the parent remains ineffective.

| Server-side heap partitioning
| (illustration of anonymous memory allocations)


Runtime environments and applications
=====================================

The component types discussed in the previous sections have in common that
they deliberately lack built-in policy but act according to a policy
supplied by their respective parents by the means of configuration.
This raises the question where those policies should come from.
The answer comes in the form of runtime environments and applications.

[tikz img/runtime_environment]
  A runtime environment manages multiple child components.

A _runtime environment_ as depicted in Figure [img/runtime_environment]
is a component that hosts child components.
As explained in the Sections [Recursive system structure] and
[Resource trading], it is thereby able to exercise control over its children
but is also responsible to manage the children's resources.
A runtime environment controls its children in three ways:

:Session routing:
  It is up to the runtime environment to decide how to route session
  requests originating from a child.
  The routing of sessions is discussed in Section [Services and sessions].

:Configuration:
  Each child obtains its configuration from its parent in the form of
  a ROM session. Using this mechanism, the runtime environment is able to feed
  policy information to its children. Of course, in order to make the policy
  be effective, the respective child has to interpret and enforce the
  configuration accordingly.

:Lifetime:
  The lifetime of a child ultimately depends on its parent. Hence, a
  runtime environment can destroy and possibly restart child components
  at any time.

With regard to management of child resources, a runtime environment can employ
a large variety of policies using two principal approaches:

:Quota management:
  Using the resource trading mechanisms introduced in Section
  [Resource trading], the runtime environment can assign resources to
  each child individually. Moreover, if a child supports the dynamic
  rebalancing protocol described in Section [Dynamic resource balancing],
  the runtime environment may even change those assignments over the lifetime
  of its children.

:Interposing services:
  Because the runtime environment controls the session routing of each
  child, it is principally able to interpose the child's use of any service
  including those normally provided by core such as
  RAM (Section [Physical memory allocation (RAM)]),
  RM (Section [Address-space management (RM)]), and
  CPU (Section [Processing-time allocation (CPU)]).
  The runtime environment may provide a locally implemented version of those
  session interfaces instead of routing session requests directly towards the
  core component.
  Internally, each session of such a local service may create a session to the
  real core service, thereby effectively wrapping core's sessions.
  This way, the runtime environment can not only observe the interaction of
  its child with core services but also implement custom resource-management
  strategies, for example, sharing one single budget among multiple children.

Canonical examples of runtime environments are the init component that
applies a policy according to its configuration, the noux runtime that
presents itself as a Unix kernel to its children, a debugger that
interposes all core services for the debugging target, or a virtual machine
monitor.

A typical _application_ is a leaf node in the component tree that merely uses
services. In practice, however, the boundary between applications and runtime
environments can be blurry.
As illustrated in Section [Component compositions], Genode fosters the
internal split of applications into several components, thereby forming
_multi-component applications_.
From the outside, such a multi-component application appears as leaf node of
the component tree but internally, it employs a further level of
componentization by executing portions of its functionality in separate child
components.
The primary incentive behind this approach is the sandboxing of untrusted
application functionality. For example, a video player may execute the video
codec within a separate child component so that a bug in the complex video
codec will not compromise the entire video-player application.


Common session interfaces
=========================

| TODO


Component compositions
======================

Enslaving services
~~~~~~~~~~~~~~~~~~

| TODO


Monitors
~~~~~~~~

| TODO


Publishing and subscribing
~~~~~~~~~~~~~~~~~~~~~~~~~~

| TODO


Untangling circular dependencies
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

| TODO



